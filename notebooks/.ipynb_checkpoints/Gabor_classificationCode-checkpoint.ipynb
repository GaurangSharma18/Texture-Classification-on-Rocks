{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39797a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import collections\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#import keras\n",
    "#import seaborn as sns\n",
    "#from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file = np.load('../patches/GborPatchesSize64/X_64_64.npz')\n",
    "X_train_file.files\n",
    "\n",
    "X_train_orignal = X_train_file['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_file = np.load('../patches/GborPatchesSize64/Y_64_64.npz')\n",
    "Y_train_file.files\n",
    "\n",
    "Y_train_orignal = Y_train_file['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_orignal.shape)\n",
    "print(Y_train_orignal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ad387",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train_orignal,Y_train_orignal,train_size=0.80,random_state=4,stratify=Y_train_orignal)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_acc(pred, gt):\n",
    "    errorSum = 0\n",
    "    accuracyOfModal = 0\n",
    "    for i in range(0, len(gt)):\n",
    "        if gt[i] != pred[i]:\n",
    "            errorSum = errorSum+1\n",
    "    accuracyOfModal = (pred.shape[0]-errorSum)/(pred.shape[0])\n",
    "    accuracyPercentage = accuracyOfModal*100\n",
    "    return accuracyPercentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# /******* define model ********/\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3),input_shape=(64, 64, 1),strides=(1, 1), padding=\"valid\", activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"valid\", activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Dropout(.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(1, 1), padding=\"valid\", activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Dropout(.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), padding=\"valid\", activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Dropout(.2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1028, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(16, activation=tf.nn.softmax))\n",
    "\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train,y_train,epochs=30,batch_size=1000,validation_split=0.25, shuffle=True)\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_file = np.load('../patches/GborPatchesSize64/X_test_64_64.npz')\n",
    "X_test_file.files\n",
    "\n",
    "X_test_orignal = X_test_file['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_file = np.load('../patches/GborPatchesSize64/Y_test_64_64.npz')\n",
    "Y_test_file.files\n",
    "\n",
    "Y_test_orignal = Y_test_file['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fabee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_orignal.shape)\n",
    "print(Y_test_orignal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test_orignal);\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted=predictions.argmax(axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6108a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test Accuracy is \",class_acc(Y_predicted,Y_test_orignal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e1a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tflow",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
