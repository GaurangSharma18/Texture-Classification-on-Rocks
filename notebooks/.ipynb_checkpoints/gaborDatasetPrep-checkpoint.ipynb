{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import collections\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#import keras\n",
    "#import seaborn as sns\n",
    "#from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af438f7",
   "metadata": {},
   "source": [
    "Making of Y Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_list = []\n",
    "prevTail=\"Amphibolite\"\n",
    "count=0\n",
    "Y_label=[]\n",
    "for filename in glob.iglob('../All53Training/**/*.png'):\n",
    "    head, tail = os.path.split(filename)\n",
    "    head, tail = os.path.split(head)\n",
    "    if tail == prevTail:\n",
    "        Y_label.append(count)\n",
    "        continue\n",
    "    else:\n",
    "        prevTail=tail\n",
    "        count+=1\n",
    "        Y_label.append(count)\n",
    "    \n",
    "#print(Y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a14a62",
   "metadata": {},
   "source": [
    "Count per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = collections.Counter(Y_label)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc183390",
   "metadata": {},
   "source": [
    "Extracting of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad262bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob('../All53Training/**/*.png'):\n",
    "    im=io.imread(filename)\n",
    "    im=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f199f4",
   "metadata": {},
   "source": [
    "Taking patches from each image\n",
    "PatchSize contains the size of patch e.g. 80*80\n",
    "numberOfRandomPatches contains random points inside the segmented regions\n",
    "numberOFActualPatches contains total number of selected patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGABORfeatures(gaborArr,y_set,y_count,img):\n",
    "    #Generate Gabor features\n",
    "    num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "    kernels = []  #Create empty list to hold all kernels that we will generate in a loop\n",
    "    for theta in range(1,6):   #Define number of thetas. Here only 2 theta values 0 and 1/4 . pi \n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3, 5):  #Sigma with values of 1 and 3\n",
    "            for lamda in np.arange(0.5, np.pi, np.pi / 4):   #Range of wavelengths\n",
    "                for gamma in (0.05, 0.2):   #Gamma values of 0.05 and 0.5\n",
    "\n",
    "                    gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "    #                print(gabor_label)\n",
    "                    ksize=5  #Try 15 for hidden image. Or 9 for others\n",
    "                    phi = 0  #0.8 for hidden image. Otherwise leave it to 0\n",
    "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)    \n",
    "                    kernels.append(kernel)\n",
    "                    #Now filter the image and add values to a new column \n",
    "                    fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)                \n",
    "                    filtered_img = fimg.reshape(-1)\n",
    "                    goodToSave = contrastFiltering(filtered_img.reshape(img.shape))\n",
    "                    \n",
    "                    if goodToSave:\n",
    "                        gaborArr.append(filtered_img.reshape(img.shape))\n",
    "                        y_set.append(y_count)\n",
    "                        num += 1  #Increment for gabor column label\n",
    "\n",
    "def contrastFiltering(img):\n",
    "    result = np.where(img == 255)\n",
    "    imgRows=result[0]\n",
    "    imgCols=result[1]\n",
    "    imgSize=len(img[0])*len(img[1])\n",
    "    whiteCount=len(imgRows)\n",
    "    whitePercentage = whiteCount*100/imgSize\n",
    "    #print(\"whitePercentage\",whiteCount*100/imgSize)\n",
    "\n",
    "    result = np.where(img == 0)\n",
    "    imgRows=result[0]\n",
    "    imgCols=result[1]\n",
    "    imgSize=len(img[0])*len(img[1])\n",
    "    blackCount=len(imgRows)\n",
    "    blackPercentage = blackCount*100/imgSize\n",
    "    #print(\"blackPercentage\",blackCount*100/imgSize)\n",
    "    \n",
    "    if whitePercentage < 30 and blackPercentage < 30:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchSize = 120\n",
    "numberOfRandomPatches=100   #Increase it if patch size increase, as most of it will get eliminate\n",
    "numberOFActualPatches = 3\n",
    "combinedPatches=[]\n",
    "Y_patchLabels=[]\n",
    "imageCount=0\n",
    "for img in image_list:\n",
    "    entropy_img = entropy(img, disk(25))\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(img, cmap='gray') #Orignal Figure\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.hist(entropy_img.flat, bins=100, range=(0,5)) #Histogram\n",
    "    thresh = threshold_otsu(entropy_img)\n",
    "\n",
    "    binary = entropy_img <= thresh #Binarize the entropy image\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(entropy_img)\n",
    "    #plt.imshow(binary)\n",
    "\n",
    "    #Sum all pixels in the scratch region (values =1)\n",
    "    #scratch_area = np.sum(binary == 1)\n",
    "    \n",
    "    # Plot random points and their patches location\n",
    "    result = np.where(binary == False)\n",
    "    imgRows=result[0]\n",
    "    imgCols=result[1]\n",
    "    randomIndex = np.random.choice(len(result[0]), numberOfRandomPatches)\n",
    "    colIndexes=imgRows[randomIndex]\n",
    "    rowIndexes=imgCols[randomIndex]\n",
    "    \n",
    "    #plt.plot(rowIndexes,colIndexes,\"*r\")\n",
    "    \n",
    "    patches = []\n",
    "    count=0\n",
    "    maxImageCount=0\n",
    "    for indxCount in rowIndexes:\n",
    "        croppedPatch=img[rowIndexes[count]:(rowIndexes[count] + patchSize), colIndexes[count]:(colIndexes[count] + patchSize)]\n",
    "        A=binary[rowIndexes[count]:(rowIndexes[count] + patchSize), colIndexes[count]:(colIndexes[count] + patchSize)]\n",
    "        \n",
    "        #select only relevent patches with 100% pattern\n",
    "        result1 = np.where(A == False)\n",
    "        if len(result1[0]) == patchSize*patchSize:\n",
    "            generateGABORfeatures(combinedPatches,Y_patchLabels,Y_label[imageCount],croppedPatch)\n",
    "            combinedPatches.append(croppedPatch)\n",
    "            patches.append(croppedPatch)\n",
    "            Y_patchLabels.append(Y_label[imageCount])\n",
    "            maxImageCount+=1\n",
    "            if (maxImageCount==numberOFActualPatches) or (indxCount == len(rowIndexes)):\n",
    "                break\n",
    "        count+=1\n",
    "    \n",
    "    ### display the image patches\n",
    "    #fig = plt.figure(figsize=(12, 12))\n",
    "    #for i, patch in enumerate(patches):\n",
    "    #    ax = fig.add_subplot(3, len(patches), len(patches)*1 + i + 1)\n",
    "    #    ax.imshow(patch, cmap=plt.cm.gray)\n",
    "    #    ax.set_xlabel('Cells %d' % (i + 1))\n",
    "    \n",
    "    imageCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combinedPatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_patchLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = collections.Counter(Y_patchLabels)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea11bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPatchesNumpy = np.array(combinedPatches)\n",
    "combinedPatchesReshaped = np.reshape(combinedPatchesNumpy,(len(combinedPatches),patchSize,patchSize))\n",
    "print(combinedPatchesReshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924989a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_patchLabelsNumpy = np.array(Y_patchLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6377bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "savez_compressed('X_120_120.npz', combinedPatchesReshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('Y_120_120.npz', Y_patchLabelsNumpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_list = []\n",
    "prevTail=\"Amphibolite\"\n",
    "count=0\n",
    "Y_label=[]\n",
    "for filename in glob.iglob('../All53Testing/**/*.png'):\n",
    "    head, tail = os.path.split(filename)\n",
    "    head, tail = os.path.split(head)\n",
    "    if tail == prevTail:\n",
    "        Y_label.append(count)\n",
    "        continue\n",
    "    else:\n",
    "        prevTail=tail\n",
    "        count+=1\n",
    "        Y_label.append(count)\n",
    "    \n",
    "#print(Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8024a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = collections.Counter(Y_label)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob('../All53Testing/**/*.png'):\n",
    "    im=io.imread(filename)\n",
    "    im=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57be964",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchSize = 64  \n",
    "numberOfRandomPatches=100   #Increase it if patch size increase, as most of it will get eliminate\n",
    "numberOFActualPatches = 3\n",
    "combinedPatches=[]\n",
    "Y_patchLabels=[]\n",
    "imageCount=0\n",
    "for img in image_list:\n",
    "    entropy_img = entropy(img, disk(25))\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(img, cmap='gray') #Orignal Figure\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.hist(entropy_img.flat, bins=100, range=(0,5)) #Histogram\n",
    "    thresh = threshold_otsu(entropy_img)\n",
    "\n",
    "    binary = entropy_img <= thresh #Binarize the entropy image\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(entropy_img)\n",
    "    #plt.imshow(binary)\n",
    "\n",
    "    #Sum all pixels in the scratch region (values =1)\n",
    "    #scratch_area = np.sum(binary == 1)\n",
    "    \n",
    "    # Plot random points and their patches location\n",
    "    result = np.where(binary == False)\n",
    "    imgRows=result[0]\n",
    "    imgCols=result[1]\n",
    "    randomIndex = np.random.choice(len(result[0]), numberOfRandomPatches)\n",
    "    colIndexes=imgRows[randomIndex]\n",
    "    rowIndexes=imgCols[randomIndex]\n",
    "    \n",
    "    #plt.plot(rowIndexes,colIndexes,\"*r\")\n",
    "    \n",
    "    patches = []\n",
    "    count=0\n",
    "    maxImageCount=0\n",
    "    for indxCount in rowIndexes:\n",
    "        croppedPatch=img[rowIndexes[count]:(rowIndexes[count] + patchSize), colIndexes[count]:(colIndexes[count] + patchSize)]\n",
    "        A=binary[rowIndexes[count]:(rowIndexes[count] + patchSize), colIndexes[count]:(colIndexes[count] + patchSize)]\n",
    "        \n",
    "        #select only relevent patches with 100% pattern\n",
    "        result1 = np.where(A == False)\n",
    "        if len(result1[0]) == patchSize*patchSize:\n",
    "            generateGABORfeatures(combinedPatches,Y_patchLabels,Y_label[imageCount],croppedPatch)\n",
    "            combinedPatches.append(croppedPatch)\n",
    "            patches.append(croppedPatch)\n",
    "            Y_patchLabels.append(Y_label[imageCount])\n",
    "            maxImageCount+=1\n",
    "            if (maxImageCount==numberOFActualPatches) or (indxCount == len(rowIndexes)):\n",
    "                break\n",
    "        count+=1\n",
    "    \n",
    "    ### display the image patches\n",
    "    #fig = plt.figure(figsize=(12, 12))\n",
    "    #for i, patch in enumerate(patches):\n",
    "    #    ax = fig.add_subplot(3, len(patches), len(patches)*1 + i + 1)\n",
    "    #    ax.imshow(patch, cmap=plt.cm.gray)\n",
    "    #    ax.set_xlabel('Cells %d' % (i + 1))\n",
    "    \n",
    "    imageCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f02fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = collections.Counter(Y_patchLabels)\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPatchesNumpy = np.array(combinedPatches)\n",
    "X_test = np.reshape(combinedPatchesNumpy,(len(combinedPatches),patchSize,patchSize))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc83756",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array(Y_patchLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fffd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "savez_compressed('X_test_120_120.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490407",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('Y_test_120_120.npz', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509b5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tflow",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
